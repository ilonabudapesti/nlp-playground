{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch 2 Exercises!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\n",
    "\n",
    "Create a variable phrase containing a list of words. Review the operations described in the previous chapter, including addition, multiplication, indexing, slicing, and sorting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"str\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-805fc2d14039>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mphrase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'meg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nyilnak'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'volgyben'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'piṭaka'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mphrase\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'ti'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"str\") to list"
     ]
    }
   ],
   "source": [
    "phrase = ['meg', 'nyilnak', 'a', 'volgyben','piṭaka']\n",
    "phrase + 'ti'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phrase + ['ti']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phrase * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phrase[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phrase.index('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phrase[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2\n",
    "\n",
    "You can write in *github* **flavored** _markup_ here.\n",
    "\n",
    "Use the corpus module to explore austen-persuasion.txt. How many word tokens does this book have? How many word types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk \n",
    "pers = nltk.corpus.gutenberg.words('austen-persuasion.txt')\n",
    "len(pers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(set(pers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3\n",
    "\n",
    "Use the Brown corpus reader nltk.corpus.brown.words() or the Web text corpus reader  nltk.corpus.webtext.words() to access some sample text in two different genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "%pprint\n",
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = brown.words(categories=['adventure','fiction'])\n",
    "b[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import webtext\n",
    "webtext.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4\n",
    "\n",
    "Read in the texts of the State of the Union addresses, using the state_union corpus reader. Count occurrences of men, women, and people in each document. What has happened to the usage of these words over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import state_union\n",
    "state_union.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "cfdsu = nltk.ConditionalFreqDist(\n",
    "            (target, fileid[:4]) \n",
    "            for fileid in state_union.fileids() \n",
    "            for w in state_union.words(fileid)\n",
    "            for target in ['man', 'woman', 'person']\n",
    "            if w.lower().startswith(target))\n",
    "cfdsu.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def president(fileid):\n",
    "    name = [s for s in fileid[5:-4] if s.isalpha()]\n",
    "    name = ''.join(name)\n",
    "    return name\n",
    "\n",
    "president('2000-Clinton.txt')\n",
    "\n",
    "cfdsuperpresident = nltk.ConditionalFreqDist(\n",
    "    (target, president(fileid))\n",
    "    for fileid in state_union.fileids()\n",
    "    for w in state_union.words(fileid)\n",
    "    for target in ['man','woman','person']\n",
    "    if w.lower().startswith(target)\n",
    "    )\n",
    "cfdsuperpresident.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not normalized. \n",
    "man:woman, man:person, woman:person ratios may be more interesting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5\n",
    "\n",
    "Investigate the holonym-meronym relations for some nouns. Remember that there are three kinds of holonym-meronym relation, so you need to use: member_meronyms(),  part_meronyms(), substance_meronyms(), member_holonyms(), part_holonyms(), and  substance_holonyms()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "wn.synsets('woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wn.synsets('man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wn.synset('woman.n.01').part_meronyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wn.synset('adult_female_body.n.01').part_meronyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wn.synset('female_body.n.01').part_meronyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for w in wn.synsets('female'):\n",
    "    print(w, w.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wn.synset('male.n.02').part_meronyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wn.synset('male_body.n.01').part_meronyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wn.synset('woman.n.01').substance_meronyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wn.synset('horse.n.01').member_holonyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6\n",
    "\n",
    "In the discussion of comparative wordlists, we created an object called translate which you could look up using words in both German and Spanish in order to get corresponding words in English. What problem might arise with this approach? Can you suggest a way to avoid this problem?\n",
    "\n",
    "A: The same word may exist both in German and in Spanish. We cannot predict which one is retrieved upon search.\n",
    "\n",
    "Have to spearate objects, de2en and es2en, within translate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "translate['Mund']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7\n",
    "\n",
    "According to Strunk and White's Elements of Style, the word however, used at the start of a sentence, means \"in whatever way\" or \"to whatever extent\", and not \"nevertheless\". They give this example of correct usage: However you advise him, he will probably do as he thinks best. (http://www.bartleby.com/141/strunk3.html) Use the concordance tool to study actual usage of this word in the various texts we have been considering. See also the LanguageLog posting \"Fossilized prejudices about 'however'\" at  http://itre.cis.upenn.edu/~myl/languagelog/archives/001913.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wn.synsets('vase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pprint\n",
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alice = nltk.Text(nltk.corpus.gutenberg.words('carroll-alice.txt'))\n",
    "alice.concordance('however')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#8 Define a conditional frequency distribution over the Names corpus \n",
    "# that allows you to see which initial letters are more frequent \n",
    "# for males vs. females (cf. 4.4).\n",
    "\n",
    "names = nltk.corpus.names\n",
    "cfdnames = nltk.ConditionalFreqDist((fileid[0:-4], name[0])\n",
    "                for fileid in names.fileids()\n",
    "                for name in names.words(fileid))\n",
    "cfdnames.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[w for w in names.words('male.txt') if w[0] == 'W']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9\n",
    "\n",
    "Pick a pair of texts and study the differences between them, in terms of vocabulary, vocabulary richness, genre, etc. Can you find pairs of words which have quite different meanings across the two texts, such as monstrous in Moby Dick and in Sense and Sensibility?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text5.concordance('spank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text6.concordance('spank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(set(text5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(set(text6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(set(text5))/len(text5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(set(text6))/len(text6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nltk.corpus.brown.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10\n",
    "Read the BBC News article: UK's Vicky Pollards 'left behind' http://news.bbc.co.uk/1/hi/education/6173441.stm. The article gives the following statistic about teen language: \"the top 20 words used, including yeah, no, but and like, account for around a third of all words.\" \n",
    "\n",
    "How many word types account for a third of all word tokens, for a variety of text sources? What do you conclude about this statistic? Read more about this on LanguageLog, at  http://itre.cis.upenn.edu/~myl/languagelog/archives/003993.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texts()\n",
    "sents()\n",
    "text1[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def topthree(text):\n",
    "    words = [w for w in text if w.isalpha()]\n",
    "    outcomes = len(words)\n",
    "    fd = nltk.FreqDist(words)\n",
    "    top3 = fd.most_common(3)\n",
    "    sum = 0\n",
    "    for w in top3:\n",
    "        sum += w[1]\n",
    "    return 100 * sum / outcomes \n",
    "\n",
    "\n",
    "topthree(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# no of word types that account for third of all word tokens\n",
    "def third(text):\n",
    "    words = [w for w in text if w.isalpha()]\n",
    "    third_of_corpus = round(len(words) / 3)\n",
    "    #print(third_of_corpus)\n",
    "    fd = nltk.FreqDist(words)\n",
    "    top50=fd.most_common(50)\n",
    "    #print(top50)\n",
    "    sum = 0\n",
    "    i = 0\n",
    "    while sum < third_of_corpus:\n",
    "        sum += top50[i][1]\n",
    "        i += 1\n",
    "    return i\n",
    "    \n",
    "print(third(text1), third(text2), third(text3), third(text4), third(text5))\n",
    "print(third(text6), third(text7), third(text8), third(text9))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11\n",
    "Investigate the table of modal distributions and look for other patterns. Try to explain them in terms of your own impressionistic understanding of the different genres. Can you find other closed classes of words that exhibit significant differences across different genres?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfd = nltk.ConditionalFreqDist((genre, word)\n",
    "        for genre in brown.categories()\n",
    "        for word in brown.words(categories=genre))\n",
    "\n",
    "genres = ['religion', 'hobbies', 'science-fiction','romance','humor']\n",
    "colors = ['white','black','red','blue','yellow','green','brown','grey','pink']\n",
    "\n",
    "cfd.tabulate(conditions = genres, samples = colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 12\n",
    "\n",
    "The CMU Pronouncing Dictionary contains multiple pronunciations for certain words. How many distinct words does it contain? What fraction of words in this dictionary have more than one possible pronunciation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133737"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries = nltk.corpus.cmudict.entries()\n",
    "len(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fir', ['F', 'ER1']), ('fire', ['F', 'AY1', 'ER0']), ('fire', ['F', 'AY1', 'R']), ('firearm', ['F', 'AY1', 'ER0', 'AA2', 'R', 'M']), ('firearm', ['F', 'AY1', 'R', 'AA2', 'R', 'M']), ('firearms', ['F', 'AY1', 'ER0', 'AA2', 'R', 'M', 'Z']), ('firearms', ['F', 'AY1', 'R', 'AA2', 'R', 'M', 'Z']), ('fireball', ['F', 'AY1', 'ER0', 'B', 'AO2', 'L'])]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries[42371:42379]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133737"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [e[0] for e in entries]\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123455"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 7, 6]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7 in [1,7]\n",
    "a = [1,7]\n",
    "if 6 not in a:\n",
    "    a.append(6)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9654"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous = ['','']\n",
    "multis = []\n",
    "for e in entries:\n",
    "    if e[0] == previous[0]:\n",
    "        if e not in multis:\n",
    "            multis.append(e)\n",
    "    previous = e\n",
    "len(multis)/len(set(words)) # about 8% or 9.6k words\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
